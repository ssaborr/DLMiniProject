{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8031584,"sourceType":"datasetVersion","datasetId":4734060}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\ndf=pd.read_csv('/kaggle/input/housing-price-dataset/Housing.csv')\ndf=df[[\n    \"id\",\n'price',\n'bedrooms',\n'bathrooms',\n'sqft_living',\n'floors',\n'waterfront',\n'view',\n'condition',\n]]\ndf = df.dropna() \ndf=df.drop_duplicates()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:04:49.960271Z","iopub.execute_input":"2025-04-21T15:04:49.960550Z","iopub.status.idle":"2025-04-21T15:04:50.032174Z","shell.execute_reply.started":"2025-04-21T15:04:49.960530Z","shell.execute_reply":"2025-04-21T15:04:50.031560Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# Calculate Q1 and Q3\nQ1 = df['price'].quantile(0.25)\nQ3 = df['price'].quantile(0.75)\nIQR = Q3 - Q1\n\n# Define bounds\nlower_bound = Q1 - 1.5 * IQR\nupper_bound = Q3 + 1.5 * IQR\n\n# Filter out outliers\ndf = df[(df['price'] >= lower_bound) & (df['price'] <= upper_bound)]\n\n# Check shape after removing outliers\nprint(\"New shape after removing price outliers:\", df.shape)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:04:50.033197Z","iopub.execute_input":"2025-04-21T15:04:50.033453Z","iopub.status.idle":"2025-04-21T15:04:50.041822Z","shell.execute_reply.started":"2025-04-21T15:04:50.033426Z","shell.execute_reply":"2025-04-21T15:04:50.041247Z"}},"outputs":[{"name":"stdout","text":"New shape after removing price outliers: (20470, 9)\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"df.to_csv('cleaned_housing.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:04:50.042593Z","iopub.execute_input":"2025-04-21T15:04:50.043037Z","iopub.status.idle":"2025-04-21T15:04:50.126752Z","shell.execute_reply.started":"2025-04-21T15:04:50.043020Z","shell.execute_reply":"2025-04-21T15:04:50.126251Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/working/cleaned_housing.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:04:50.128625Z","iopub.execute_input":"2025-04-21T15:04:50.128848Z","iopub.status.idle":"2025-04-21T15:04:50.147180Z","shell.execute_reply.started":"2025-04-21T15:04:50.128831Z","shell.execute_reply":"2025-04-21T15:04:50.146446Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:16:50.155048Z","iopub.execute_input":"2025-04-21T15:16:50.155379Z","iopub.status.idle":"2025-04-21T15:16:50.169009Z","shell.execute_reply.started":"2025-04-21T15:16:50.155356Z","shell.execute_reply":"2025-04-21T15:16:50.168446Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"       Unnamed: 0          id     price  bedrooms  bathrooms  sqft_living  \\\n0               0  7229300521  231300.0         2       1.00         1180   \n1               1  6414100192  538000.0         3       2.25         2570   \n2               2  5631500400  180000.0         2       1.00          770   \n3               3  2487200875  604000.0         4       3.00         1960   \n4               4  1954400510  510000.0         3       2.00         1680   \n...           ...         ...       ...       ...        ...          ...   \n20465       21608   263000018  360000.0         3       2.50         1530   \n20466       21609  6600060120  400000.0         4       2.50         2310   \n20467       21610  1523300141  402101.0         2       0.75         1020   \n20468       21611   291310100  400000.0         3       2.50         1600   \n20469       21612  1523300157  325000.0         2       0.75         1020   \n\n       floors  waterfront  view  condition  \n0         1.0           0     0          3  \n1         2.0           0     0          3  \n2         1.0           0     0          3  \n3         1.0           0     0          5  \n4         1.0           0     0          3  \n...       ...         ...   ...        ...  \n20465     3.0           0     0          3  \n20466     2.0           0     0          3  \n20467     2.0           0     0          3  \n20468     2.0           0     0          3  \n20469     2.0           0     0          3  \n\n[20470 rows x 10 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>id</th>\n      <th>price</th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n      <th>sqft_living</th>\n      <th>floors</th>\n      <th>waterfront</th>\n      <th>view</th>\n      <th>condition</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>7229300521</td>\n      <td>231300.0</td>\n      <td>2</td>\n      <td>1.00</td>\n      <td>1180</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>6414100192</td>\n      <td>538000.0</td>\n      <td>3</td>\n      <td>2.25</td>\n      <td>2570</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5631500400</td>\n      <td>180000.0</td>\n      <td>2</td>\n      <td>1.00</td>\n      <td>770</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>2487200875</td>\n      <td>604000.0</td>\n      <td>4</td>\n      <td>3.00</td>\n      <td>1960</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1954400510</td>\n      <td>510000.0</td>\n      <td>3</td>\n      <td>2.00</td>\n      <td>1680</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>20465</th>\n      <td>21608</td>\n      <td>263000018</td>\n      <td>360000.0</td>\n      <td>3</td>\n      <td>2.50</td>\n      <td>1530</td>\n      <td>3.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>20466</th>\n      <td>21609</td>\n      <td>6600060120</td>\n      <td>400000.0</td>\n      <td>4</td>\n      <td>2.50</td>\n      <td>2310</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>20467</th>\n      <td>21610</td>\n      <td>1523300141</td>\n      <td>402101.0</td>\n      <td>2</td>\n      <td>0.75</td>\n      <td>1020</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>20468</th>\n      <td>21611</td>\n      <td>291310100</td>\n      <td>400000.0</td>\n      <td>3</td>\n      <td>2.50</td>\n      <td>1600</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>20469</th>\n      <td>21612</td>\n      <td>1523300157</td>\n      <td>325000.0</td>\n      <td>2</td>\n      <td>0.75</td>\n      <td>1020</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>20470 rows × 10 columns</p>\n</div>"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# --- Chargement et preprocessing ---\ndf = pd.read_csv('/kaggle/working/cleaned_housing.csv')\nfeatures = df.drop(columns=['id', 'Unnamed: 0'])\nscaler = StandardScaler()\nfeatures_scaled = scaler.fit_transform(features)\n\n# --- TensorFlow dataset ---\nfeatures_tensor = tf.convert_to_tensor(features_scaled, dtype=tf.float32)\n\n# --- Génération de triplets à partir des données brutes ---\ndef generate_triplets(features, num_triplets=5000):\n    triplets = []\n    n = len(features)\n    for _ in range(num_triplets):\n        anchor = np.random.randint(0, n)\n        positive = (anchor + 1) % n\n        negative = np.random.randint(0, n)\n        while negative == anchor or negative == positive:\n            negative = np.random.randint(0, n)\n        triplets.append((anchor, positive, negative))\n    return np.array(triplets)\n\ntriplet_indices = generate_triplets(features_scaled, num_triplets=5000)\nanchor = tf.gather(features_tensor, triplet_indices[:, 0])\npositive = tf.gather(features_tensor, triplet_indices[:, 1])\nnegative = tf.gather(features_tensor, triplet_indices[:, 2])\n\ntriplet_dataset = tf.data.Dataset.from_tensor_slices((anchor, positive, negative)).batch(3000)\n\n# --- Modèle d'embedding puissant ---\nembedding_model = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=(features.shape[1],)),  # ici 9\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dense(32)\n])\n\n# --- Triplet Loss ---\ndef triplet_loss(a, p, n, margin=1.0):\n    pos_dist = tf.reduce_sum(tf.square(a - p), axis=1)\n    neg_dist = tf.reduce_sum(tf.square(a - n), axis=1)\n    loss = tf.maximum(pos_dist - neg_dist + margin, 0.0)\n    return tf.reduce_mean(loss)\n\n# --- Entraînement ---\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\nprint(\"\\n--- Entraînement avec Triplet Loss ---\")\nepochs = 200\nfor epoch in range(epochs):\n    epoch_loss = 0\n    for step, (a, p, n) in enumerate(triplet_dataset):\n        with tf.GradientTape() as tape:\n            a_embed = embedding_model(a)\n            p_embed = embedding_model(p)\n            n_embed = embedding_model(n)\n            loss = triplet_loss(a_embed, p_embed, n_embed)\n        grads = tape.gradient(loss, embedding_model.trainable_variables)\n        optimizer.apply_gradients(zip(grads, embedding_model.trainable_variables))\n        epoch_loss += loss.numpy()\n    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {epoch_loss / (step + 1):.4f}\")\n\n# --- Embeddings finaux ---\nfinal_embeddings = embedding_model(features_tensor).numpy()\n\n# --- Recommandation (top-k voisins) ---\ndef recommend_similar(house_id, top_k=5):\n    idx = df[df['id'] == house_id].index[0]\n    query_embedding = final_embeddings[idx:idx+1]\n    sims = cosine_similarity(query_embedding, final_embeddings)[0]\n    sims[idx] = -np.inf  # Exclure la maison elle-même\n    top_k_indices = np.argsort(sims)[-top_k:][::-1]\n    return df.iloc[top_k_indices]\n\n# --- Exemple ---\nhouse_id = df['id'].iloc[0]\nprint(f\"\\nMaisons similaires à la maison avec ID {house_id} :\")\nprint(recommend_similar(house_id, top_k=5))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:06:58.420042Z","iopub.execute_input":"2025-04-21T15:06:58.420708Z","iopub.status.idle":"2025-04-21T15:07:17.984431Z","shell.execute_reply.started":"2025-04-21T15:06:58.420685Z","shell.execute_reply":"2025-04-21T15:07:17.983742Z"}},"outputs":[{"name":"stdout","text":"\n--- Entraînement avec Triplet Loss ---\nEpoch 1/200 - Loss: 1.2644\nEpoch 2/200 - Loss: 1.0147\nEpoch 3/200 - Loss: 0.9559\nEpoch 4/200 - Loss: 0.9342\nEpoch 5/200 - Loss: 0.9250\nEpoch 6/200 - Loss: 0.9148\nEpoch 7/200 - Loss: 0.9062\nEpoch 8/200 - Loss: 0.8971\nEpoch 9/200 - Loss: 0.8882\nEpoch 10/200 - Loss: 0.8805\nEpoch 11/200 - Loss: 0.8708\nEpoch 12/200 - Loss: 0.8604\nEpoch 13/200 - Loss: 0.8502\nEpoch 14/200 - Loss: 0.8413\nEpoch 15/200 - Loss: 0.8309\nEpoch 16/200 - Loss: 0.8219\nEpoch 17/200 - Loss: 0.8132\nEpoch 18/200 - Loss: 0.8041\nEpoch 19/200 - Loss: 0.7952\nEpoch 20/200 - Loss: 0.7879\nEpoch 21/200 - Loss: 0.7772\nEpoch 22/200 - Loss: 0.7685\nEpoch 23/200 - Loss: 0.7603\nEpoch 24/200 - Loss: 0.7519\nEpoch 25/200 - Loss: 0.7436\nEpoch 26/200 - Loss: 0.7325\nEpoch 27/200 - Loss: 0.7211\nEpoch 28/200 - Loss: 0.7132\nEpoch 29/200 - Loss: 0.7033\nEpoch 30/200 - Loss: 0.6922\nEpoch 31/200 - Loss: 0.6872\nEpoch 32/200 - Loss: 0.6769\nEpoch 33/200 - Loss: 0.6752\nEpoch 34/200 - Loss: 0.6646\nEpoch 35/200 - Loss: 0.6549\nEpoch 36/200 - Loss: 0.6474\nEpoch 37/200 - Loss: 0.6384\nEpoch 38/200 - Loss: 0.6316\nEpoch 39/200 - Loss: 0.6246\nEpoch 40/200 - Loss: 0.6220\nEpoch 41/200 - Loss: 0.6175\nEpoch 42/200 - Loss: 0.6077\nEpoch 43/200 - Loss: 0.6096\nEpoch 44/200 - Loss: 0.6035\nEpoch 45/200 - Loss: 0.5964\nEpoch 46/200 - Loss: 0.5793\nEpoch 47/200 - Loss: 0.5801\nEpoch 48/200 - Loss: 0.5762\nEpoch 49/200 - Loss: 0.5862\nEpoch 50/200 - Loss: 0.5888\nEpoch 51/200 - Loss: 0.5993\nEpoch 52/200 - Loss: 0.6063\nEpoch 53/200 - Loss: 0.5922\nEpoch 54/200 - Loss: 0.5740\nEpoch 55/200 - Loss: 0.5587\nEpoch 56/200 - Loss: 0.5526\nEpoch 57/200 - Loss: 0.5467\nEpoch 58/200 - Loss: 0.5313\nEpoch 59/200 - Loss: 0.5209\nEpoch 60/200 - Loss: 0.5148\nEpoch 61/200 - Loss: 0.5060\nEpoch 62/200 - Loss: 0.4934\nEpoch 63/200 - Loss: 0.4870\nEpoch 64/200 - Loss: 0.4786\nEpoch 65/200 - Loss: 0.4719\nEpoch 66/200 - Loss: 0.4663\nEpoch 67/200 - Loss: 0.4622\nEpoch 68/200 - Loss: 0.4555\nEpoch 69/200 - Loss: 0.4547\nEpoch 70/200 - Loss: 0.4548\nEpoch 71/200 - Loss: 0.4513\nEpoch 72/200 - Loss: 0.4518\nEpoch 73/200 - Loss: 0.4551\nEpoch 74/200 - Loss: 0.4530\nEpoch 75/200 - Loss: 0.4408\nEpoch 76/200 - Loss: 0.4419\nEpoch 77/200 - Loss: 0.4292\nEpoch 78/200 - Loss: 0.4275\nEpoch 79/200 - Loss: 0.4134\nEpoch 80/200 - Loss: 0.4135\nEpoch 81/200 - Loss: 0.4105\nEpoch 82/200 - Loss: 0.4039\nEpoch 83/200 - Loss: 0.4005\nEpoch 84/200 - Loss: 0.3937\nEpoch 85/200 - Loss: 0.3923\nEpoch 86/200 - Loss: 0.3837\nEpoch 87/200 - Loss: 0.3812\nEpoch 88/200 - Loss: 0.3724\nEpoch 89/200 - Loss: 0.3751\nEpoch 90/200 - Loss: 0.3696\nEpoch 91/200 - Loss: 0.3661\nEpoch 92/200 - Loss: 0.3647\nEpoch 93/200 - Loss: 0.3602\nEpoch 94/200 - Loss: 0.3593\nEpoch 95/200 - Loss: 0.3528\nEpoch 96/200 - Loss: 0.3489\nEpoch 97/200 - Loss: 0.3475\nEpoch 98/200 - Loss: 0.3396\nEpoch 99/200 - Loss: 0.3451\nEpoch 100/200 - Loss: 0.3462\nEpoch 101/200 - Loss: 0.3397\nEpoch 102/200 - Loss: 0.3448\nEpoch 103/200 - Loss: 0.3385\nEpoch 104/200 - Loss: 0.3357\nEpoch 105/200 - Loss: 0.3300\nEpoch 106/200 - Loss: 0.3375\nEpoch 107/200 - Loss: 0.3272\nEpoch 108/200 - Loss: 0.3393\nEpoch 109/200 - Loss: 0.3408\nEpoch 110/200 - Loss: 0.3334\nEpoch 111/200 - Loss: 0.3412\nEpoch 112/200 - Loss: 0.3199\nEpoch 113/200 - Loss: 0.3250\nEpoch 114/200 - Loss: 0.3142\nEpoch 115/200 - Loss: 0.3078\nEpoch 116/200 - Loss: 0.3001\nEpoch 117/200 - Loss: 0.2980\nEpoch 118/200 - Loss: 0.2928\nEpoch 119/200 - Loss: 0.2895\nEpoch 120/200 - Loss: 0.2911\nEpoch 121/200 - Loss: 0.2824\nEpoch 122/200 - Loss: 0.2733\nEpoch 123/200 - Loss: 0.2717\nEpoch 124/200 - Loss: 0.2716\nEpoch 125/200 - Loss: 0.2679\nEpoch 126/200 - Loss: 0.2649\nEpoch 127/200 - Loss: 0.2617\nEpoch 128/200 - Loss: 0.2624\nEpoch 129/200 - Loss: 0.2574\nEpoch 130/200 - Loss: 0.2625\nEpoch 131/200 - Loss: 0.2566\nEpoch 132/200 - Loss: 0.2556\nEpoch 133/200 - Loss: 0.2589\nEpoch 134/200 - Loss: 0.2642\nEpoch 135/200 - Loss: 0.2702\nEpoch 136/200 - Loss: 0.2762\nEpoch 137/200 - Loss: 0.2733\nEpoch 138/200 - Loss: 0.2701\nEpoch 139/200 - Loss: 0.2659\nEpoch 140/200 - Loss: 0.2552\nEpoch 141/200 - Loss: 0.2480\nEpoch 142/200 - Loss: 0.2571\nEpoch 143/200 - Loss: 0.2483\nEpoch 144/200 - Loss: 0.2498\nEpoch 145/200 - Loss: 0.2508\nEpoch 146/200 - Loss: 0.2616\nEpoch 147/200 - Loss: 0.2593\nEpoch 148/200 - Loss: 0.2651\nEpoch 149/200 - Loss: 0.2600\nEpoch 150/200 - Loss: 0.2398\nEpoch 151/200 - Loss: 0.2291\nEpoch 152/200 - Loss: 0.2368\nEpoch 153/200 - Loss: 0.2228\nEpoch 154/200 - Loss: 0.2148\nEpoch 155/200 - Loss: 0.2278\nEpoch 156/200 - Loss: 0.2252\nEpoch 157/200 - Loss: 0.2257\nEpoch 158/200 - Loss: 0.2143\nEpoch 159/200 - Loss: 0.2128\nEpoch 160/200 - Loss: 0.2203\nEpoch 161/200 - Loss: 0.2265\nEpoch 162/200 - Loss: 0.2267\nEpoch 163/200 - Loss: 0.2192\nEpoch 164/200 - Loss: 0.2306\nEpoch 165/200 - Loss: 0.2218\nEpoch 166/200 - Loss: 0.2228\nEpoch 167/200 - Loss: 0.2127\nEpoch 168/200 - Loss: 0.2049\nEpoch 169/200 - Loss: 0.2061\nEpoch 170/200 - Loss: 0.1994\nEpoch 171/200 - Loss: 0.2047\nEpoch 172/200 - Loss: 0.2016\nEpoch 173/200 - Loss: 0.1957\nEpoch 174/200 - Loss: 0.1894\nEpoch 175/200 - Loss: 0.1857\nEpoch 176/200 - Loss: 0.1852\nEpoch 177/200 - Loss: 0.1893\nEpoch 178/200 - Loss: 0.1937\nEpoch 179/200 - Loss: 0.1897\nEpoch 180/200 - Loss: 0.1856\nEpoch 181/200 - Loss: 0.1792\nEpoch 182/200 - Loss: 0.1788\nEpoch 183/200 - Loss: 0.1798\nEpoch 184/200 - Loss: 0.1812\nEpoch 185/200 - Loss: 0.1785\nEpoch 186/200 - Loss: 0.1769\nEpoch 187/200 - Loss: 0.1722\nEpoch 188/200 - Loss: 0.1733\nEpoch 189/200 - Loss: 0.1647\nEpoch 190/200 - Loss: 0.1667\nEpoch 191/200 - Loss: 0.1645\nEpoch 192/200 - Loss: 0.1735\nEpoch 193/200 - Loss: 0.1753\nEpoch 194/200 - Loss: 0.1749\nEpoch 195/200 - Loss: 0.1721\nEpoch 196/200 - Loss: 0.1672\nEpoch 197/200 - Loss: 0.1666\nEpoch 198/200 - Loss: 0.1668\nEpoch 199/200 - Loss: 0.1672\nEpoch 200/200 - Loss: 0.1725\n\nMaisons similaires à la maison avec ID 7229300521 :\n       Unnamed: 0          id     price  bedrooms  bathrooms  sqft_living  \\\n12195       12835  8961800035  229000.0         2        1.0         1190   \n8089         8519  6668900155  225000.0         2        1.0         1170   \n10346       10876  3352401090  238950.0         2        1.0         1190   \n8208         8643  3223049158  222200.0         2        1.0         1210   \n8120         8553  8018600870  224000.0         2        1.0         1150   \n\n       floors  waterfront  view  condition  \n12195     1.0           0     0          3  \n8089      1.0           0     0          3  \n10346     1.0           0     0          3  \n8208      1.0           0     0          3  \n8120      1.0           0     0          3  \n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"def evaluate_recommendations(df, final_embeddings, top_k=5, sample_ratio=0.2):\n    reciprocal_ranks = []\n    topk_hits = 0\n    total = len(df)\n    \n    # Prendre un échantillon de 20% des données\n    sample_size = int(sample_ratio * total)\n    sampled_indices = np.random.choice(total, size=sample_size, replace=False)\n\n    print(f\"\\n--- Évaluation sur un échantillon de {sample_size} maisons ---\")\n    for count, i in enumerate(sampled_indices):\n        try:\n            query_embedding = final_embeddings[i]\n            house_id = df['id'].iloc[i]\n\n            # Similarités avec toutes les maisons\n            sims = cosine_similarity(query_embedding.reshape(1, -1), final_embeddings)[0]\n            sims[i] = -np.inf  # on ignore la maison elle-même\n\n            # Vrai plus proche voisin\n            true_closest_idx = np.argmax(sims)\n            true_closest_id = df['id'].iloc[true_closest_idx]\n\n            # Recommandations du modèle\n            recs = recommend_similar(house_id, top_k=top_k)\n            rec_ids = recs['id'].values\n\n            # Top-K hit\n            if true_closest_id in rec_ids:\n                topk_hits += 1\n\n            # MRR\n            if true_closest_id in rec_ids:\n                rank = np.where(rec_ids == true_closest_id)[0][0] + 1\n                reciprocal_ranks.append(1.0 / rank)\n            else:\n                reciprocal_ranks.append(0.0)\n\n            if count % 100 == 0:\n                print(f\"{count}/{sample_size} maisons traitées...\")\n\n        except Exception as e:\n            print(f\"Erreur à l'index {i} : {e}\")\n            continue\n\n    topk_accuracy = topk_hits / sample_size\n    mrr = np.mean(reciprocal_ranks)\n\n    print(\"\\n--- Résultats de l'Évaluation ---\")\n    print(f\"Top-{top_k} Accuracy : {topk_accuracy:.4f}\")\n    print(f\"MRR : {mrr:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:07:22.212953Z","iopub.execute_input":"2025-04-21T15:07:22.213263Z","iopub.status.idle":"2025-04-21T15:07:22.220725Z","shell.execute_reply.started":"2025-04-21T15:07:22.213241Z","shell.execute_reply":"2025-04-21T15:07:22.219940Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"evaluate_recommendations(df, final_embeddings, top_k=5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:07:30.912762Z","iopub.execute_input":"2025-04-21T15:07:30.913050Z","iopub.status.idle":"2025-04-21T15:07:51.367428Z","shell.execute_reply.started":"2025-04-21T15:07:30.913029Z","shell.execute_reply":"2025-04-21T15:07:51.366711Z"}},"outputs":[{"name":"stdout","text":"\n--- Évaluation sur un échantillon de 4094 maisons ---\n0/4094 maisons traitées...\n100/4094 maisons traitées...\n200/4094 maisons traitées...\n300/4094 maisons traitées...\n400/4094 maisons traitées...\n500/4094 maisons traitées...\n600/4094 maisons traitées...\n700/4094 maisons traitées...\n800/4094 maisons traitées...\n900/4094 maisons traitées...\n1000/4094 maisons traitées...\n1100/4094 maisons traitées...\n1200/4094 maisons traitées...\n1300/4094 maisons traitées...\n1400/4094 maisons traitées...\n1500/4094 maisons traitées...\n1600/4094 maisons traitées...\n1700/4094 maisons traitées...\n1800/4094 maisons traitées...\n1900/4094 maisons traitées...\n2000/4094 maisons traitées...\n2100/4094 maisons traitées...\n2200/4094 maisons traitées...\n2300/4094 maisons traitées...\n2400/4094 maisons traitées...\n2500/4094 maisons traitées...\n2600/4094 maisons traitées...\n2700/4094 maisons traitées...\n2800/4094 maisons traitées...\n2900/4094 maisons traitées...\n3000/4094 maisons traitées...\n3100/4094 maisons traitées...\n3200/4094 maisons traitées...\n3300/4094 maisons traitées...\n3400/4094 maisons traitées...\n3500/4094 maisons traitées...\n3600/4094 maisons traitées...\n3700/4094 maisons traitées...\n3800/4094 maisons traitées...\n3900/4094 maisons traitées...\n4000/4094 maisons traitées...\n\n--- Résultats de l'Évaluation ---\nTop-5 Accuracy : 0.9939\nMRR : 0.9905\n","output_type":"stream"}],"execution_count":38},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def recommend_by_features(input_features_dict, top_k=10):\n    \"\"\"\n    input_features_dict: a dict where keys are feature names and values are feature values.\n    Example:\n    {\n        'bedrooms': 3,\n        'bathrooms': 2,\n        'sqft_living': 1500,\n        ...\n    }\n    \"\"\"\n    # Convert input features into same order as training data\n    input_df = pd.DataFrame([input_features_dict])\n    input_scaled = scaler.transform(input_df)\n    input_tensor = tf.convert_to_tensor(input_scaled, dtype=tf.float32)\n\n    # Get embedding\n    input_embedding = embedding_model(input_tensor).numpy()\n\n    # Compute cosine similarity\n    sims = cosine_similarity(input_embedding, final_embeddings)[0]\n    top_k_indices = np.argsort(sims)[-top_k:][::-1]\n    \n    return df.iloc[top_k_indices]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:15:35.069728Z","iopub.execute_input":"2025-04-21T15:15:35.070043Z","iopub.status.idle":"2025-04-21T15:15:35.075362Z","shell.execute_reply.started":"2025-04-21T15:15:35.070022Z","shell.execute_reply":"2025-04-21T15:15:35.074644Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"# Example input — adapt based on your dataset's columns\ninput_features = {\n     'price':16500,\n    'bedrooms': 1.5,\n    'bathrooms': 1,\n    'sqft_living': 1000,\n    \n    'floors': 1,\n    'waterfront': 0,\n    'view': 0,\n    'condition': 3,\n  \n}\n\n\n\ntop_similar = recommend_by_features(input_features, top_k=10)\nprint(top_similar)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T15:21:23.203899Z","iopub.execute_input":"2025-04-21T15:21:23.204297Z","iopub.status.idle":"2025-04-21T15:21:23.223377Z","shell.execute_reply.started":"2025-04-21T15:21:23.204272Z","shell.execute_reply":"2025-04-21T15:21:23.222615Z"}},"outputs":[{"name":"stdout","text":"       Unnamed: 0          id     price  bedrooms  bathrooms  sqft_living  \\\n15186       15986    87000213  129000.0         2        1.0         1150   \n2459         2589  5061300030  134000.0         2        1.5          980   \n5528         5816  7568700480  153000.0         2        1.0         1140   \n13861       14581  6929602721   95000.0         2        1.0          960   \n3229         3397  2172000750  160000.0         2        1.0         1180   \n12923       13601  8698600395  150000.0         2        1.0         1250   \n15864       16714  1322049150   85000.0         2        1.0          910   \n9605        10105  5466310060  139500.0         2        1.5         1230   \n17524       18468  7999600180   83000.0         2        1.0          900   \n2954         3108  1721801591   89950.0         1        1.0          570   \n\n       floors  waterfront  view  condition  \n15186     1.0           0     0          3  \n2459      2.0           0     0          3  \n5528      1.0           0     0          3  \n13861     1.0           0     0          3  \n3229      1.0           0     0          3  \n12923     1.0           0     0          3  \n15864     1.0           0     0          3  \n9605      2.0           0     0          3  \n17524     1.0           0     0          3  \n2954      1.0           0     0          3  \n","output_type":"stream"}],"execution_count":51}]}